ğŸ“¹ Surveillance VidÃ©o AvancÃ©e avec YOLO
Ce projet implÃ©mente un systÃ¨me de surveillance vidÃ©o basÃ© sur le modÃ¨le YOLO (You Only Look Once) pour la dÃ©tection d'objets en temps rÃ©el. Il permet d'identifier et de suivre des objets, notamment des personnes, dans une vidÃ©o, en mettant en Ã©vidence ceux qui entrent dans une zone d'intÃ©rÃªt prÃ©dÃ©finie. Ce systÃ¨me est conÃ§u pour des applications de sÃ©curitÃ©, offrant une dÃ©tection rapide et prÃ©cise pour alerter les opÃ©rateurs en cas de situation anormale.
ğŸ“œ Description et UtilitÃ©
Ce projet utilise des techniques avancÃ©es de vision par ordinateur et d'apprentissage automatique pour analyser des flux vidÃ©o. En combinant le modÃ¨le YOLO avec une zone d'intÃ©rÃªt dÃ©finie par un polygone, il dÃ©tecte les objets (principalement des personnes) et signale leur prÃ©sence dans une zone spÃ©cifique. Ses applications incluent :

Surveillance de zones sensibles (parkings, entrÃ©es, zones sÃ©curisÃ©es).
DÃ©tection proactive pour la sÃ©curitÃ© publique.
Analyse en temps rÃ©el pour une intervention rapide.

âœ¨ FonctionnalitÃ©s

ğŸ•µï¸â€â™‚ï¸ DÃ©tection d'objets : Identification en temps rÃ©el des objets (personnes, vÃ©hicules, etc.) dans une vidÃ©o Ã  l'aide du modÃ¨le YOLOv8.
ğŸ“ Zone d'intÃ©rÃªt : Mise en Ã©vidence des objets situÃ©s dans une zone dÃ©finie par un polygone configurable.
ğŸ¨ Visualisation : Dessin de cadres rouges autour des objets dÃ©tectÃ©s et affichage de la zone d'intÃ©rÃªt en magenta.
ğŸ–±ï¸ Interaction : Affichage des coordonnÃ©es RGB et des positions des pixels via un callback de souris.
ğŸ“¡ Traitement vidÃ©o : Analyse frame par frame d'une vidÃ©o ou d'un flux en direct.

ğŸ› ï¸ PrÃ©requis
Pour exÃ©cuter ce projet, vous aurez besoin des Ã©lÃ©ments suivants :

SystÃ¨me d'exploitation : Windows, macOS, ou Linux.
Python : Version 3.8 ou supÃ©rieure.
BibliothÃ¨ques Python :
opencv-python pour le traitement vidÃ©o.
ultralytics pour le modÃ¨le YOLO.
pandas pour la manipulation des donnÃ©es.
numpy pour les calculs numÃ©riques.


ModÃ¨le YOLO : Fichier yolov8s.pt (inclus dans le dÃ©pÃ´t ou tÃ©lÃ©chargeable via Ultralytics).
Fichier des classes COCO : Fichier coco.txt contenant la liste des classes d'objets dÃ©tectables.
VidÃ©o d'entrÃ©e : Une vidÃ©o au format .mp4 (exemple : VIDEO.mp4).

ğŸš€ Installation et Mise en Marche
Suivez ces Ã©tapes pour configurer et exÃ©cuter le projet :

Clonez le dÃ©pÃ´t GitHub :
git clone https://github.com/HaMzaCheh/Advanced-Video-Surveillance-YOLO.git
cd Advanced-Video-Surveillance-YOLO


CrÃ©ez un environnement virtuel (recommandÃ©) :
python -m venv venv
source venv/bin/activate  # Sur Windows : venv\Scripts\activate


Installez les dÃ©pendances :
pip install opencv-python ultralytics pandas numpy


TÃ©lÃ©chargez le modÃ¨le YOLO :

Le fichier yolov8s.pt est tÃ©lÃ©chargeable automatiquement par Ultralytics lors de l'exÃ©cution du script, ou vous pouvez le placer manuellement dans le dossier du projet.


Ajoutez les fichiers nÃ©cessaires :

Assurez-vous que le fichier coco.txt est dans le rÃ©pertoire du projet.
Placez votre vidÃ©o d'entrÃ©e (par exemple, VIDEO.mp4) dans le rÃ©pertoire ou mettez Ã  jour le chemin dans le script main.py.


Lancez le script :
python main.py



ğŸ–¥ï¸ Utilisation
Une fois le script lancÃ©, voici comment interagir avec le systÃ¨me :

Visualisation : Une fenÃªtre nommÃ©e Ecran_detection affiche la vidÃ©o avec :
Les cadres rouges autour des personnes dÃ©tectÃ©es dans la zone d'intÃ©rÃªt.
La zone d'intÃ©rÃªt dÃ©limitÃ©e par un polygone magenta.


Interaction avec la souris : DÃ©placez le curseur sur la fenÃªtre pour afficher les coordonnÃ©es (x, y) et les valeurs BGR des pixels dans la console.
Sortie : Appuyez sur la touche ESC pour quitter l'application.
Personnalisation : Modifiez les coordonnÃ©es de la zone d'intÃ©rÃªt dans main.py (variable area) pour ajuster la zone surveillÃ©e.

ğŸ§  Architecture du Code
Le script principal (main.py) est structurÃ© comme suit :

Chargement du modÃ¨le : Utilisation de yolov8s.pt via la bibliothÃ¨que ultralytics.
Lecture de la vidÃ©o : Utilisation d'OpenCV pour lire les frames de la vidÃ©o.
DÃ©tection d'objets : Application du modÃ¨le YOLO pour identifier les objets dans chaque frame.
Zone d'intÃ©rÃªt : VÃ©rification si les objets (personnes) se trouvent dans la zone dÃ©finie Ã  l'aide de cv2.pointPolygonTest.
Visualisation : Dessin des cadres autour des objets dÃ©tectÃ©s et de la zone d'intÃ©rÃªt.
Interaction : Gestion des Ã©vÃ©nements de souris pour afficher les informations de pixels.

Le code est modulaire et peut Ãªtre adaptÃ© pour d'autres vidÃ©os ou zones d'intÃ©rÃªt.
ğŸ¥ Simulation / DÃ©mo

Lancez le script main.py comme dÃ©crit dans la section Installation.
La fenÃªtre Ecran_detection affiche la vidÃ©o avec les dÃ©tections en temps rÃ©el.
DÃ©placez la souris sur la fenÃªtre pour voir les informations de pixels dans la console.
Testez avec diffÃ©rentes vidÃ©os ou modifiez les coordonnÃ©es de la zone d'intÃ©rÃªt pour observer les changements.

Pour une dÃ©monstration, utilisez une vidÃ©o contenant des personnes dans un environnement surveillÃ© (par exemple, un parking ou une entrÃ©e). Le systÃ¨me mettra en Ã©vidence les personnes entrant dans la zone d'intÃ©rÃªt.
ğŸ¤ Contribution
Nous accueillons toutes les contributions ! Pour contribuer :

Forkez le dÃ©pÃ´t.
CrÃ©ez une branche pour vos modifications :git checkout -b ma-nouvelle-fonctionnalite


Faites vos modifications et testez-les.
Soumettez une pull request avec une description claire de vos changements.

Veuillez respecter les conventions de codage Python (PEP 8) et inclure des tests si possible.

ğŸ’¬ Note Finale
Merci d'explorer ce projet ! Si vous avez des questions, des idÃ©es d'amÃ©lioration, ou des retours, n'hÃ©sitez pas Ã  ouvrir une issue ou Ã  me contacter. Votre feedback est prÃ©cieux pour faire Ã©voluer ce systÃ¨me de surveillance ! ğŸš€
