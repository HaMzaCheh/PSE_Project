# ğŸ“¹ Surveillance VidÃ©o AvancÃ©e avec YOLO

Ce projet met en Å“uvre un systÃ¨me de **surveillance vidÃ©o en temps rÃ©el** utilisant le modÃ¨le d'intelligence artificielle **YOLO (You Only Look Once)**, reconnu pour sa rapiditÃ© et sa prÃ©cision dans la dÃ©tection dâ€™objets. ConÃ§u principalement pour identifier et suivre des personnes, ce systÃ¨me analyse chaque image (frame) dâ€™un flux vidÃ©o afin de dÃ©tecter la prÃ©sence dâ€™objets spÃ©cifiques au sein dâ€™une zone dâ€™intÃ©rÃªt dÃ©finie par lâ€™utilisateur via un polygone.

GrÃ¢ce Ã  sa capacitÃ© Ã  traiter les vidÃ©os en temps rÃ©el, il offre une solution efficace et rÃ©active pour des environnements oÃ¹ la sÃ©curitÃ© est cruciale. Le systÃ¨me ne se limite pas Ã  la simple dÃ©tection : il met en Ã©vidence uniquement les objets situÃ©s dans une zone prÃ©dÃ©finie, permettant ainsi de focaliser la surveillance sur des espaces stratÃ©giques ou sensibles.

Ce projet est idÃ©al pour les organisations souhaitant automatiser la surveillance vidÃ©o et rÃ©duire le besoin dâ€™intervention humaine constante, tout en augmentant la rapiditÃ© de dÃ©tection dâ€™Ã©vÃ©nements critiques.

---

## ğŸ“œ Description et UtilitÃ©

Le cÅ“ur du systÃ¨me repose sur des techniques avancÃ©es de **vision par ordinateur** et dâ€™**apprentissage profond**, permettant dâ€™extraire en temps rÃ©el des informations pertinentes dâ€™un flux vidÃ©o. Ã€ chaque image analysÃ©e, le modÃ¨le YOLO identifie les objets (personnes, vÃ©hicules, etc.) prÃ©sents, puis vÃ©rifie sâ€™ils se trouvent dans la zone dâ€™intÃ©rÃªt, dÃ©finie prÃ©cisÃ©ment par un polygone paramÃ©trable.

Lâ€™intÃ©rÃªt principal rÃ©side dans la surveillance ciblÃ©e, qui permet :

* **Surveillance de parkings, accÃ¨s, et zones sensibles** : La dÃ©tection ciblÃ©e dans ces espaces critiques amÃ©liore la sÃ©curitÃ© en alertant immÃ©diatement en cas dâ€™intrusion ou de mouvement suspect.  
* **SÃ©curitÃ© publique proactive et prÃ©vention** : En dÃ©tectant rapidement la prÃ©sence dâ€™individus dans des zones stratÃ©giques, le systÃ¨me facilite lâ€™intervention avant quâ€™un incident ne se produise.  
* **Analyse vidÃ©o en temps rÃ©el pour intervention rapide** : La capacitÃ© Ã  traiter les donnÃ©es vidÃ©o en direct offre un avantage essentiel dans les scÃ©narios dâ€™urgence, permettant aux opÃ©rateurs dâ€™agir instantanÃ©ment sur les alertes gÃ©nÃ©rÃ©es.

Ce systÃ¨me sâ€™adresse aussi bien aux entreprises, administrations publiques, organismes de sÃ©curitÃ©, quâ€™Ã  toute structure ayant besoin dâ€™une surveillance vidÃ©o intelligente et automatisÃ©e. Sa modularitÃ© et sa flexibilitÃ© permettent dâ€™adapter facilement la zone dâ€™intÃ©rÃªt et le type dâ€™objets dÃ©tectÃ©s en fonction des besoins spÃ©cifiques du site surveillÃ©.


---

## âœ¨ FonctionnalitÃ©s clÃ©s

* ğŸ•µï¸â€â™‚ï¸ **DÃ©tection dâ€™objets en temps rÃ©el** (personnes, vÃ©hicules, etc.) avec YOLOv8
* ğŸ“ **Zone dâ€™intÃ©rÃªt paramÃ©trable** par polygone (affichage magenta Ã  lâ€™Ã©cran)
* ğŸ¨ **Visualisation intuitive** avec cadres rouges sur les objets dÃ©tectÃ©s dans la zone
* ğŸ–±ï¸ **Interaction via souris** : coordonnÃ©es (x, y) et valeurs BGR des pixels affichÃ©es dans la console
* ğŸ“¡ **Traitement frame par frame** Ã  partir dâ€™un fichier vidÃ©o ou dâ€™un flux direct

---

## ğŸ› ï¸ PrÃ©requis

* SystÃ¨me dâ€™exploitation : Windows, macOS ou Linux
* Python version 3.8 ou supÃ©rieure
* BibliothÃ¨ques Python nÃ©cessaires :

  * `opencv-python`
  * `ultralytics`
  * `pandas`
  * `numpy`
* ModÃ¨le YOLO (`yolov8s.pt`) accessible localement ou tÃ©lÃ©chargÃ© automatiquement
* Fichier de classes COCO (`coco.txt`) dans le rÃ©pertoire du projet
* VidÃ©o dâ€™entrÃ©e au format `.mp4` (exemple : `VIDEO.mp4`)

---

## ğŸš€ Installation et dÃ©marrage rapide

1. **Cloner le dÃ©pÃ´t :**

   ```bash
   git clone https://github.com/HaMzaCheh/Advanced-Video-Surveillance-YOLO.git
   cd Advanced-Video-Surveillance-YOLO
   ```

2. **CrÃ©er et activer un environnement virtuel (fortement recommandÃ©) :**

   ```bash
   python -m venv venv
   source venv/bin/activate  # Sur Windows : venv\Scripts\activate
   ```

3. **Installer les dÃ©pendances :**

   ```bash
   pip install opencv-python ultralytics pandas numpy
   ```

4. **PrÃ©parer les fichiers nÃ©cessaires :**

   * Placer `coco.txt` dans le dossier du projet
   * Mettre votre vidÃ©o `.mp4` (exemple : `VIDEO.mp4`) dans le mÃªme dossier ou modifier son chemin dans `main.py`

5. **Lancer lâ€™application :**

   ```bash
   python main.py
   ```

---

## ğŸ–¥ï¸ Utilisation

* Une fenÃªtre nommÃ©e `Ecran_detection` sâ€™ouvre et affiche la vidÃ©o avec les objets dÃ©tectÃ©s.
* Les objets dÃ©tectÃ©s **dans la zone dâ€™intÃ©rÃªt** sont entourÃ©s dâ€™un cadre rouge.
* La zone dâ€™intÃ©rÃªt est tracÃ©e en magenta.
* DÃ©placez la souris sur la fenÃªtre pour voir sâ€™afficher dans la console les coordonnÃ©es du pixel sous le curseur ainsi que sa couleur BGR.
* Appuyez sur la touche `ESC` pour fermer lâ€™application.
* Pour modifier la zone surveillÃ©e, ajustez la variable `area` dans `main.py` (coordonnÃ©es du polygone).

---

## ğŸ§  Architecture et fonctionnement du code

* Chargement du modÃ¨le YOLOv8 via la bibliothÃ¨que `ultralytics`.
* Lecture et traitement vidÃ©o image par image avec OpenCV.
* DÃ©tection des objets dans chaque frame analysÃ©e.
* VÃ©rification de la position des objets dÃ©tectÃ©s au sein de la zone dÃ©finie via `cv2.pointPolygonTest`.
* Affichage des rÃ©sultats (zones, cadres) et gestion des interactions souris.
* Code modulaire, facilement adaptable Ã  diffÃ©rents flux vidÃ©o ou zones dâ€™intÃ©rÃªt.

---

## ğŸ¥ DÃ©monstration / Simulation

* ExÃ©cutez le script `python main.py` pour voir la dÃ©tection en temps rÃ©el.
* Testez avec diverses vidÃ©os ou modifiez la zone dâ€™intÃ©rÃªt pour observer lâ€™effet.
* RecommandÃ© : utiliser une vidÃ©o contenant des personnes dans un espace surveillÃ© (parking, entrÃ©e, etc.) pour visualiser les alertes.

---

## ğŸ¤ Contribution

Les contributions sont chaleureusement bienvenues !

* Forkez ce dÃ©pÃ´t
* CrÃ©ez une branche pour votre fonctionnalitÃ© :

  ```bash
  git checkout -b ma-nouvelle-fonctionnalite
  ```
* Effectuez vos modifications et testez-les soigneusement
* Soumettez une pull request claire et documentÃ©e

Merci de respecter les bonnes pratiques Python (PEP 8) et dâ€™inclure des tests quand câ€™est possible.

---

ğŸ’¬ **Merci dâ€™avoir consultÃ© ce projet ! Vos retours et suggestions sont prÃ©cieux pour son amÃ©lioration continue ğŸš€**
Nâ€™hÃ©sitez pas Ã  ouvrir une issue ou Ã  me contacter via GitHub.
