````markdown
# ğŸ“¹ Surveillance VidÃ©o AvancÃ©e avec YOLO

Un systÃ¨me de **surveillance vidÃ©o en temps rÃ©el** basÃ© sur le modÃ¨le **YOLO (You Only Look Once)** pour la dÃ©tection et le suivi dâ€™objets, principalement des personnes, dans une zone dâ€™intÃ©rÃªt dÃ©finie.  
IdÃ©al pour des applications de sÃ©curitÃ© nÃ©cessitant une dÃ©tection rapide et prÃ©cise.

---

## ğŸ“œ Description et UtilitÃ©

Ce projet utilise la vision par ordinateur et lâ€™apprentissage automatique pour analyser un flux vidÃ©o, dÃ©tecter des objets, et signaler leur prÃ©sence dans une zone prÃ©dÃ©finie par un polygone.  
Applications typiques :  
- Surveillance de parkings, entrÃ©es, zones sensibles  
- SÃ©curitÃ© publique proactive  
- Analyse vidÃ©o en temps rÃ©el pour intervention rapide

---

## âœ¨ FonctionnalitÃ©s

- ğŸ•µï¸â€â™‚ï¸ DÃ©tection dâ€™objets (personnes, vÃ©hicules, etc.) en temps rÃ©el avec YOLOv8  
- ğŸ“ Zone dâ€™intÃ©rÃªt configurable par polygone (affichage magenta)  
- ğŸ¨ Visualisation avec cadres rouges autour des objets dÃ©tectÃ©s dans la zone  
- ğŸ–±ï¸ Interaction souris affichant coordonnÃ©es et valeurs RGB des pixels  
- ğŸ“¡ Traitement vidÃ©o frame par frame depuis fichier ou flux direct

---

## ğŸ› ï¸ PrÃ©requis

- OS : Windows, macOS ou Linux  
- Python 3.8+  
- BibliothÃ¨ques Python :  
  - `opencv-python`  
  - `ultralytics`  
  - `pandas`  
  - `numpy`  
- ModÃ¨le YOLO (`yolov8s.pt`) disponible localement ou tÃ©lÃ©chargÃ© automatiquement  
- Fichier des classes COCO (`coco.txt`) dans le dossier projet  
- VidÃ©o dâ€™entrÃ©e au format `.mp4` (ex : `VIDEO.mp4`)

---

## ğŸš€ Installation et Mise en Marche

1. Cloner le dÃ©pÃ´t :  
   ```bash
   git clone https://github.com/HaMzaCheh/Advanced-Video-Surveillance-YOLO.git
   cd Advanced-Video-Surveillance-YOLO
````

2. CrÃ©er et activer un environnement virtuel (recommandÃ©) :

   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows : venv\Scripts\activate
   ```

3. Installer les dÃ©pendances :

   ```bash
   pip install opencv-python ultralytics pandas numpy
   ```

4. Placer les fichiers nÃ©cessaires :

   * `coco.txt` dans le dossier projet
   * VidÃ©o `.mp4` (ex: `VIDEO.mp4`) ou modifier le chemin dans `main.py`

5. Lancer le script :

   ```bash
   python main.py
   ```

---

## ğŸ–¥ï¸ Utilisation

* Une fenÃªtre `Ecran_detection` affiche la vidÃ©o analysÃ©e.
* Les objets dÃ©tectÃ©s dans la zone dâ€™intÃ©rÃªt sont encadrÃ©s en rouge.
* La zone dâ€™intÃ©rÃªt est dessinÃ©e en magenta.
* DÃ©placez la souris dans la fenÃªtre pour afficher coordonnÃ©es (x,y) et valeurs BGR des pixels dans la console.
* Appuyez sur `ESC` pour quitter.
* Pour modifier la zone surveillÃ©e, ajustez la variable `area` dans `main.py`.

---

## ğŸ§  Architecture du Code

* **Chargement du modÃ¨le** YOLOv8 via `ultralytics`.
* **Lecture vidÃ©o** frame par frame avec OpenCV.
* **DÃ©tection dâ€™objets** dans chaque frame.
* **VÃ©rification** si les objets dÃ©tectÃ©s sont dans la zone dÃ©finie (`cv2.pointPolygonTest`).
* **Visualisation** des dÃ©tections et de la zone dâ€™intÃ©rÃªt.
* **Gestion dâ€™interactions souris** pour affichage des infos pixel.

Le code est modulaire et facilement adaptable Ã  dâ€™autres vidÃ©os ou zones.

---

## ğŸ¥ Simulation / DÃ©mo

* Lancez `python main.py` et observez la dÃ©tection en temps rÃ©el.
* Testez avec diffÃ©rentes vidÃ©os ou modifiez la zone dâ€™intÃ©rÃªt pour voir lâ€™impact.
* Utilisez une vidÃ©o avec des personnes dans un environnement surveillÃ© (parking, entrÃ©e, etc.) pour une dÃ©monstration rÃ©aliste.

---

## ğŸ¤ Contribution

Contributions bienvenues !

* Forkez le projet
* CrÃ©ez une branche dÃ©diÃ©e :

  ```bash
  git checkout -b ma-nouvelle-fonctionnalite
  ```
* Testez vos modifications
* Ouvrez une pull request claire et documentÃ©e

Merci de respecter PEP 8 et dâ€™inclure des tests si possible.

---

ğŸ’¬ **Merci dâ€™explorer ce projet ! Vos retours sont prÃ©cieux pour lâ€™amÃ©liorer ğŸš€**

```
